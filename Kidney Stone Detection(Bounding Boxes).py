# -*- coding: utf-8 -*-
"""Untitled21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fDREhC02gZg2SBgeiBqq6_z7kGEjcNIQ
"""


import numpy as np # linear algebra
import pandas as pd # data processing


import os
for dirname, _, filenames in os.walk('/content/drive/MyDrive/archive'):
    for filename in filenames:
        print(os.path.join(dirname, filename))


import random
from PIL import Image, ImageDraw
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import torch
import torchvision
from torchvision import transforms as T
from torchvision.models.detection. faster_rcnn import FastRCNNPredictor

# converting yolo darknet normalized labels to CoCo format x,y,w,h

def yolo_to_coco(x_cen_norm,y_cen_norm,width_norm,height_norm,image_width,image_height):
    box_width=width_norm*image_width
    box_height=height_norm*image_height
    box_center_x=((2*x_cen_norm*image_width)-box_width)/2
    box_center_y=((2*y_cen_norm*image_height)-box_height)/2
    return int(box_center_x),int(box_center_y),int(box_width),int(box_height)

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
data=pd.DataFrame(columns=['image_id','class_id','x_min','y_min','x_max','y_max'])
labels_path='/content/drive/MyDrive/archive/train/labels'
train_path='/content/drive/MyDrive/archive/train/images'
for k in os.listdir(train_path):
    img=cv2.imread(train_path+"/"+k)
    label=pd.read_csv(labels_path+"/"+k.replace(".jpg",'.txt'), delim_whitespace=True, names=['class_id','x_min','y_min','x_max','y_max'],header=None)
    for i in range(len(label)):
        x,y,w,h=yolo_to_coco(label['x_min'][i],label['y_min'][i],label['x_max'][i],label['y_max'][i],img.shape[1],img.shape[0])
        label['x_min'][i]=x
        label['y_min'][i]=y

        label['x_max'][i]=x+w
        label['y_max'][i]=y+h
        label['class_id'][i]=1
    label['image_id']=k
    data=pd.concat([data,label])

data

data.reset_index(drop=True,inplace=True)

data

unique_imgs=data.image_id.unique()

unique_imgs

import torch
from torchvision import transforms as T

class CustDat(torch.utils.data.Dataset):
  def __init__(self, df, unique_imgs, indices):
    self.df = df
    self.unique_imgs = unique_imgs
    self.indices= indices

  def __len__(self):
    return len(self.indices)

  def __getitem__(self, idx):
    image_name= self.unique_imgs[self.indices[idx]]
    boxes= self.df[self.df.image_id == image_name].values[:, 2:].astype("float")
    img = Image.open("/content/drive/MyDrive/archive/train/images/" + image_name ).convert('RGB')
    labels = torch.ones((boxes.shape[0]), dtype = torch.int64)
    target ={}
    target["boxes"] = torch.tensor (boxes)
    target["label"] = labels
    return T.ToTensor() (img), target

from sklearn.model_selection import train_test_split
train_inds,val_inds=train_test_split(range(unique_imgs.shape[0]),test_size=0.1)

unique_imgs[val_inds]

def custom_collate(data):
  return data

train_dl=torch.utils.data.DataLoader(CustDat(data,unique_imgs,train_inds),
                                     batch_size=8,
                                     shuffle=True,
                                     collate_fn=custom_collate,
                                     pin_memory=True if torch.cuda.is_available() else False)

val_dl=torch.utils.data.DataLoader(CustDat(data,unique_imgs,val_inds),
                                     batch_size=8,
                                     shuffle=True,
                                     collate_fn=custom_collate,
                                     pin_memory=True if torch.cuda.is_available() else False)

import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = True)
num_classes = 2
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

device= torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
device

optimizer= torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)
num_epochs=10

frfrom PIL import Image

def compute_epoch_accuracy(model, dataloader):
    total_correct = 0
    total_examples = 0

    for data in dataloader:
        imgs = []
        targets = []

        for d in data:
            imgs.append(d[0].to(device))
            targ = {}
            targ["boxes"] = d[1]["boxes"].to(device)
            targ["labels"] = d[1]["label"].to(device)
            targets.append(targ)

        if not targets:  # Skip iteration if targets are empty
            continue

        with torch.no_grad():
            # Get predictions
            predictions = model(imgs)
            pred_boxes = predictions[0]["boxes"]
            pred_scores = predictions[0]["scores"]
            pred_labels = torch.ones(pred_boxes.shape[0], dtype=torch.int64, device=device)

            # Calculate mAP
            batch_ap = compute_ap(targets[0]["boxes"], targets[0]["labels"], pred_boxes, pred_scores, device=device)
            total_correct += batch_ap
            total_examples += 1

    # Average accuracy
    average_accuracy = total_correct / total_examples

    return average_accuracy

def compute_epoch_precision_recall(model, dataloader):
    all_true_positives = 0
    all_predicted_positives = 0
    all_actual_positives = 0

    for data in dataloader:
        imgs = []
        targets = []

        for d in data:
            imgs.append(d[0].to(device))
            targ = {}
            targ["boxes"] = d[1]["boxes"].to(device)
            targ["labels"] = d[1]["label"].to(device)
            targets.append(targ)

        if not targets:  # Skip iteration if targets are empty
            continue

        with torch.no_grad():
            # Get predictions
            predictions = model(imgs)
            pred_boxes = predictions[0]["boxes"]
            pred_scores = predictions[0]["scores"]
            pred_labels = torch.ones(pred_boxes.shape[0], dtype=torch.int64, device=device)

            # Calculate precision and recall
            true_positives, predicted_positives, actual_positives = compute_precision_recall(targets[0]["boxes"], targets[0]["labels"], pred_boxes, pred_scores)
            all_true_positives += true_positives
            all_predicted_positives += predicted_positives
            all_actual_positives += actual_positives

    # Calculate precision and recall
    precision = all_true_positives / all_predicted_positives
    recall = all_true_positives / all_actual_positives

    return precision, recall

model.to(device)
for epoch in range(num_epochs):
    epoch_loss = 0

    for batch_idx, data in enumerate(train_dl):
        imgs = []
        targets = []

        for d in data:
            imgs.append(d[0].to(device))
            targ = {}
            targ["boxes"] = d[1]["boxes"].to(device)
            targ["labels"] = d[1]["label"].to(device)
            targets.append(targ)

        if not targets:  # Skip iteration if targets are empty
            continue

        # Forward pass
        loss_dict = model(imgs, targets)
        loss = sum(loss for loss in loss_dict.values())

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Accumulate loss
        epoch_loss += loss.item()

    # Calculate accuracy (mAP) on validation set
    val_accuracy = compute_epoch_accuracy(model, val_dl)

    # Calculate precision and recall on validation set
    val_precision, val_recall = compute_epoch_precision_recall(model, val_dl)

    # Average loss and accuracy
    average_loss = epoch_loss / len(train_dl)

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}")

print("Training finished.")
om PIL import Image
model.to(device)
for epochs in range (num_epochs):
    epoch_loss = 0
    best_metric = float('inf')
    best_epoch = -1
    for data in train_dl:
        imgs = []
        targets = []
        for d in data:
            imgs.append(d[0].to(device))
            targ= {}
            targ["boxes"] = d[1]["boxes"].to(device)
            targ["labels"] = d[1]["label"].to(device)
            targets.append(targ)
        loss_dict = model(imgs, targets)
        loss = sum(v for v in loss_dict.values())
        epoch_loss += loss.cpu().detach().numpy()
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if epoch_loss < best_metric:
        # Update the best metric and best epoch
            best_metric = epoch_loss
            best_epoch = epochs
            # Save the model with the current best performance
            torch.save(model.state_dict(), "best_model.pth")
    print(epoch_loss)

import seaborn as sns
from sklearn.metrics import confusion_matrix

def compute_confusion_matrix(model, dataloader):
    all_labels = []
    all_predictions = []

    for data in dataloader:
        imgs = []
        targets = []

        for d in data:
            imgs.append(d[0].to(device))
            targ = {}
            targ["boxes"] = d[1]["boxes"].to(device)
            targ["labels"] = d[1]["label"].to(device)
            targets.append(targ)

        if not targets:  # Skip iteration if targets are empty
            continue

        with torch.no_grad():
            # Get predictions
            predictions = model(imgs)
            pred_boxes = predictions[0]["boxes"]
            pred_scores = predictions[0]["scores"]
            pred_labels = torch.ones(pred_boxes.shape[0], dtype=torch.int64, device=device)

            # Add true labels and predicted labels to lists
            for target in targets:
                all_labels.extend(target["labels"].cpu().numpy())
            for label in pred_labels:
                all_predictions.extend(label.cpu().numpy())

    # Compute confusion matrix
    cm = confusion_matrix(all_labels, all_predictions)
    return cm

# Compute confusion matrix
conf_matrix = compute_confusion_matrix(model, val_dl)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

model.eval()
data=iter(val_dl).__next__()

from IPython.display import display
from PIL import Image, ImageDraw

from torchvision.ops import box_iou

def compute_ap(gt_boxes, gt_labels, pred_boxes, pred_scores, iou_threshold=0.45, class_label=1, device='cpu'):


    # Sort predictions by score
    sort_idx = torch.argsort(pred_scores, descending=True)
    pred_boxes = pred_boxes[sort_idx]
    pred_scores = pred_scores[sort_idx]

    # Compute IoU between predicted and ground truth boxes
    iou = box_iou(pred_boxes, gt_boxes)

    # Find the best matching ground truth box for each prediction
    match_idx = iou.argmax(dim=1)
    match_iou = iou[range(iou.shape[0]), match_idx]

    # Initialize true positive and false positive arrays
    tp = torch.zeros_like(pred_scores)
    fp = torch.zeros_like(pred_scores)

    # Keep track of which ground truth boxes have already been matched
    matched = torch.zeros(gt_boxes.shape[0], dtype=torch.bool)

    # Loop over predictions
    for i in range(pred_scores.shape[0]):
        # If the prediction matches a ground truth box with IoU above the threshold
        if match_iou[i] >= iou_threshold:
            # If the ground truth box has not already been matched
            if not matched[match_idx[i]]:
                # True positive
                tp[i] = 1
                matched[match_idx[i]] = True
            else:
                # False positive (duplicate detection)
                fp[i] = 1
        else:
            # False positive
            fp[i] = 1

    # Compute precision and recall
    tp_cumsum = tp.cumsum(dim=0)
    fp_cumsum = fp.cumsum(dim=0)
    precision = tp_cumsum / (tp_cumsum + fp_cumsum)
    recall = tp_cumsum / gt_boxes.shape[0]

    # Add start and end points to precision-recall curve
    precision = torch.cat([torch.tensor([1.], device=device), precision, torch.tensor([0.], device=device)])
    recall = torch.cat([torch.tensor([0.], device=device), recall, torch.tensor([1.], device=device)])

    # Compute average precision as the area under the precision-recall curve
    ap = -torch.trapz(precision, recall)

    return ap

from torchvision.ops import box_iou

def compute_ap(gt_boxes, gt_labels, pred_boxes, pred_scores, iou_threshold=0.45, class_label=1, device='cpu'):


    # Sort predictions by score
    sort_idx = torch.argsort(pred_scores, descending=True)
    pred_boxes = pred_boxes[sort_idx]
    pred_scores = pred_scores[sort_idx]

    # Compute IoU between predicted and ground truth boxes
    iou = box_iou(pred_boxes, gt_boxes)

    # Find the best matching ground truth box for each prediction
    match_idx = iou.argmax(dim=1)
    match_iou = iou[range(iou.shape[0]), match_idx]

    # Initialize true positive and false positive arrays
    tp = torch.zeros_like(pred_scores)
    fp = torch.zeros_like(pred_scores)

    # Keep track of which ground truth boxes have already been matched
    matched = torch.zeros(gt_boxes.shape[0], dtype=torch.bool)

    # Loop over predictions
    for i in range(pred_scores.shape[0]):
        # If the prediction matches a ground truth box with IoU above the threshold
        if match_iou[i] >= iou_threshold:
            # If the ground truth box has not already been matched
            if not matched[match_idx[i]]:
                # True positive
                tp[i] = 1
                matched[match_idx[i]] = True
            else:
                # False positive (duplicate detection)
                fp[i] = 1
        else:
            # False positive
            fp[i] = 1

    # Compute precision and recall
    tp_cumsum = tp.cumsum(dim=0)
    fp_cumsum = fp.cumsum(dim=0)
    precision = tp_cumsum / (tp_cumsum + fp_cumsum)
    recall = tp_cumsum / gt_boxes.shape[0]

    # Add start and end points to precision-recall curve
    precision = torch.cat([torch.tensor([1.], device=device), precision, torch.tensor([0.], device=device)])
    recall = torch.cat([torch.tensor([0.], device=device), recall, torch.tensor([1.], device=device)])

    # Compute average precision as the area under the precision-recall curve
    ap = -torch.trapz(precision, recall)

    return ap

def disp_imgs(dl):
    for data in dl:
        length = len(data)
        i=0
        for i in range (len(data)):
            imgs = data[i][0]
            targets = data[i][1]
            boxes = targets['boxes']
            boxes = boxes.type(torch.int)
            labels = targets['label']
            i+=1

            output = model([imgs.to(device)])
    #         print(i," - ",output)
            out_bbox = output[0]["boxes"]
    #         print("out_bbox"," - ",out_bbox)
            out_scores = output[0]["scores"]
            keep = torchvision.ops.nms(out_bbox, out_scores, 0.45)
            im = (imgs.permute(1, 2, 0).cpu().detach().numpy() * 255).astype('uint8')
            vsample = Image.fromarray(im)
            draw = ImageDraw.Draw(vsample)
            for box in out_bbox[keep]:
                draw.rectangle(list(box), fill=None, outline="red")
            display(vsample)

    ap = compute_ap(boxes.to(device), labels.to(device), out_bbox.to(device), out_scores.to(device), class_label=1, device=device)

    print("mAP = ",ap)

disp_imgs(val_dl)